
# üß† End-to-End ML Project Using AWS SageMaker: Titanic Survival Prediction

This project walks through a real-world ML workflow on **Amazon SageMaker** ‚Äî from data to deployment and automation ‚Äî with certification alignment for AWS ML Associate and AI Practitioner.

---

## üë®üèΩ‚Äçüíª Author

**Samuel Ogah**  
_Principal DevSecOps, Security & AI Engineer_  
üîó [LinkedIn](https://www.linkedin.com/in/sogah)  
üì´ [GitHub](https://github.com/sogah2023)

---

## üñºÔ∏è Architecture Diagram
![image](https://github.com/user-attachments/assets/8fd1bd48-36a4-4641-bb8c-1fae208713eb)

  
> Includes: S3 ‚Üí Data Wrangler ‚Üí Training ‚Üí HPO ‚Üí Endpoint ‚Üí Monitor ‚Üí Pipelines ‚Üí IAM ‚Üí GuardDuty
 
- Stage 1: Data Ingestion & Cleaning 
- Stage 2: Model Dev with Studio/Autopilot   
- Stage 3: Training & HPO Infrastructure  
- Stage 4: Real-time & Batch Deployment Setup  
- Stage 5: Monitoring & SHAP Bias Flow
- Stage 6: CI/CD Automation with IAM/VPC

---

## üß≠ Learning Map: Beginner to Advanced

| Level        | What to Focus On                                   | Tools & Keywords                          |
|--------------|----------------------------------------------------|-------------------------------------------|
| Beginner     | Notebooks, JumpStart, Endpoints                    | Studio IDE, Autopilot, Deploy             |
| Intermediate | Data Wrangler, Estimator, HPO, Clarify             | Experiments, Model Monitor, Feature Store |
| Advanced     | Pipelines, IAM, CI/CD, VPC, Security Guardrails    | Step Functions, KMS, GuardDuty            |

---

## üß© Project Scenario: Real-World Simulation

üßôüèΩ‚Äç‚ôÇÔ∏è Imagine this:

> ‚ÄúYou‚Äôre hired to build a machine learning system that predicts Titanic survival, but your manager demands:
>
> ‚úÖ Automation  
> ‚úÖ Monitoring & Bias Reports  
> ‚úÖ Endpoint deployment & Explainability  
> ‚úÖ Audit compliance & security readiness‚Äù

Your task is to bring it to life using **SageMaker‚Äôs end-to-end tools**!

---

## üìÅ Dataset

üéØ Titanic Dataset  
üîó [Click to Download (from GitHub)](https://github.com/sogah2023/AI-ML/blob/main/Titanic%20Dataset.csv?raw=true)

Upload to S3 before launching the notebook.

---

## üöÄ Project Stages

| Stage      | Tools & Services                                                                 | Output                                      |
|------------|-----------------------------------------------------------------------------------|---------------------------------------------|
| üì• Data Prep  | Data Wrangler, Processing Jobs, Feature Store                                    | Cleaned S3 data or features in Feature Store |
| üîß Dev        | Notebooks, JumpStart, Autopilot                                                  | Model candidates & EDA                      |
| üéØ Training   | Estimator, Spot Training, Hyperparameter Tuner, Debugger, Experiments            | model.tar.gz, tuning reports                |
| üöÄ Deployment | Real-time Endpoints, Batch Transform, Neo                                        | Live endpoint or batch prediction files     |
| üß† Monitoring | Clarify, Model Monitor, CloudWatch                                                | SHAP reports, bias logs, CloudWatch alerts  |
| üîÅ Automation | Pipelines, Step Functions, IAM, VPC, KMS, GuardDuty                               | Automated pipeline, secure audit trail      |

---

## üìò How to Use This Repo

1. Clone this repo into SageMaker Studio or local environment
2. Upload the Titanic dataset to S3
3. Open and run the Jupyter Notebook: `SageMaker_ML_Titanic_Complete.ipynb`
4. Follow each stage ‚Äî Data Prep ‚Üí Dev ‚Üí Train ‚Üí Deploy ‚Üí Monitor ‚Üí Automate

---

## üß† Certification Readiness

### Covered for AWS ML Associate & Practitioner:

- ‚úÖ SageMaker Studio IDE, Autopilot, and Pipelines
- ‚úÖ HPO, Debugger, Spot Training
- ‚úÖ Feature Store, Batch Transform, Endpoints
- ‚úÖ SHAP & Clarify for explainability
- ‚úÖ IAM, KMS, GuardDuty for security
- ‚úÖ End-to-end ML workflow understanding

üíª **Notebook Reference**:  
üîó [SageMaker_ML_Titanic_Complete.ipynb](https://github.com/sogah2023/AI-ML/blob/main/SageMaker_ML_Titanic_Complete.ipynb)

---

üíª **Notebook Reference for each stage 1-6**  
üîó [SageMaker_ML_Titanic_Complete.ipynb](https://github.com/sogah2023/AI-ML/blob/main/SageMaker_ML_Titanic_Complete.ipynb)


## üß± Step-by-Step ML Lifecycle (Titanic Survival Prediction)

### ‚úÖ Stage 1: Data Ingestion & Cleaning
1. Download Titanic dataset from GitHub.
2. Upload it to your S3 bucket using SageMaker SDK.
3. Launch SageMaker **Data Wrangler** in Studio.
4. Connect to your S3 source and import the dataset.
5. Clean null values (drop or impute).
6. Encode `Sex`, `Embarked`, and other categorical variables.
7. Normalize `Fare`, `Age`.
8. Save the cleaned data to S3 or register it to Feature Store.

üß™ Code Reference: See notebook section **‚ÄúStage 1 ‚Äì Data Preparation‚Äù**

---

### ‚úÖ Stage 2: Model Development
1. Open SageMaker Studio notebook.
2. Perform Exploratory Data Analysis (EDA) with Seaborn and Pandas.
3. Visualize correlations, distributions, and identify features.
4. Use **JumpStart** to run sample models (optional).
5. Launch **Autopilot** to test AutoML pipelines.
6. Evaluate candidate model accuracy, precision, recall.

üß™ Code Reference: See notebook section **‚ÄúStage 2 ‚Äì Model Development‚Äù**

---

### ‚úÖ Stage 3: Training & Hyperparameter Tuning
1. Choose **XGBoost** or custom training script.
2. Set up Estimator in SageMaker.
3. Use **Pipe Mode** or **File Mode** to load data from S3.
4. Configure and launch a **Training Job** on `ml.m5.large`.
5. Define hyperparameter ranges for tuning.
6. Run a **Hyperparameter Tuner** to find optimal configuration.
7. Use **Experiments** to track trials and metadata.
8. Integrate **Debugger** to monitor training metrics and avoid overfitting.

üß™ Code Reference: See notebook section **‚ÄúStage 3 ‚Äì Model Training & Optimization‚Äù**

---

### ‚úÖ Stage 4: Deployment
1. Register best model to **SageMaker Model Registry**.
2. Deploy the model to a real-time **SageMaker Endpoint**.
3. Create predictor and test prediction requests with sample JSON or array input.
4. For batch predictions, use **Batch Transform** with CSV from S3.
5. Confirm inference latency and success metrics.

üß™ Code Reference: See notebook section **‚ÄúStage 4 ‚Äì Deployment‚Äù**

---

### ‚úÖ Stage 5: Monitoring & Explainability
1. Enable **Model Monitor** for real-time endpoint.
2. Create a monitoring schedule to capture data and statistics.
3. Use **Clarify Processor** to run SHAP explainability jobs.
4. Analyze bias across gender, class, or age fields.
5. Output all reports to **S3**.
6. View metrics and logs in **CloudWatch** for alerts.

üß™ Code Reference: See notebook section **‚ÄúStage 5 ‚Äì Monitoring & Explainability‚Äù**

---

### ‚úÖ Stage 6: Automation & Security
1. Build a **SageMaker Pipeline** for end-to-end orchestration:
   - Data Wrangler ‚Üí Processing ‚Üí Training ‚Üí Evaluation ‚Üí Deployment
2. Use **Step Functions** to trigger re-training cycles (e.g., weekly).
3. Create and attach **IAM roles** for least-privilege access.
4. Configure **VPC** for isolated compute resources.
5. Apply **KMS** for encryption of data at rest.
6. Enable **GuardDuty** and **CloudTrail** for logging and threat detection.

üß™ Code Reference: See notebook section **‚ÄúStage 6 ‚Äì Automation & Security‚Äù**

---
## üìú License

MIT License ‚Äî free to use, adapt, and improve.

---
 
> ‚úâÔ∏è [Open an issue or contact me on LinkedIn](https://www.linkedin.com/in/sogah)  
> ‚≠ê Star this repo to follow updates!
